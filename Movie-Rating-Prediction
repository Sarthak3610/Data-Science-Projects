import numpy as np
import pandas as pd

dfx = pd.read_csv('Trainnlp.csv')
dfy = pd.read_csv('Test.csv')

ly = dfx.values
y_train = ly[:,-1]
print(y_train)
print(dfy.sample(5))

from nltk.tokenize import RegexpTokenizer
from nltk.stem.porter import PorterStemmer
from nltk.corpus import stopwords

tokenizer = RegexpTokenizer(r'\w+')
en_stopwords = set(stopwords.words('english'))
ps = PorterStemmer()

def getstemmedreview(reviews):
    review = reviews.lower()
    review = reviews.replace("<br /><br />", "")
    tokens = tokenizer.tokenize(review)
    new_tokens = [token for token in tokens if token not in en_stopwords]
    stemmed_tokens = [ps.stem(token) for token in new_tokens]
    cleaned_review = ' '.join(stemmed_tokens)
    return cleaned_review
    
dfx["review"]=dfx["review"].apply(getstemmedreview)
dfy["review"]=dfy["review"].apply(getstemmedreview)

file=open("out.txt",'w',encoding = "utf8")
for review in dfx["review"].values :
    file.write(review)
    file.write("\n")
file=open("outtest.txt",'w',encoding = "utf8")

for review in dfy["review"].values :
    file.write(review)
    file.write("\n")

train_y = print(dfy["review"])
train_x = print(dfx["review"])

x_clean = [line.rstrip('\n') for line in open('out.txt')]
xt_clean = [line.rstrip('\n') for line in open('outtest.txt')]
#print(x_clean[:6])

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer()
x_vec = cv.fit_transform(x_clean)
xt_vec = cv.transform(xt_clean)

from sklearn.naive_bayes import MultinomialNB, BernoulliNB
mnb = MultinomialNB()
mnb.fit(x_vec, y_train)
y_test = mnb.predict(xt_vec)
arr = np.array(y_test)
print(arr)
df = pd.DataFrame(arr)
df.columns = ['index']
df.to_csv('submission_movie.csv', encoding = 'utf-8')

bnb = BernoulliNB()
bnb.fit(x_vec, y_train)
b_test = bnb.predict(xt_vec)
print(b_test)
arr = np.array(b_test)
df = pd.DataFrame(arr)
df.columns = ['index']
df.to_csv('submission_movie.csv', encoding = 'utf-8')
